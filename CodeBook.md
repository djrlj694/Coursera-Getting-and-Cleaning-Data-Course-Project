Coursera: Getting and Cleaning Data Course Project

# Code Book

This code book describes the variables and statistical summaries calculated (along with units of measurement) in addition to transformations performed to clean up the data.

## Background

The data discussed here are the result of human activity recognition experiments carried out with a group of 30 volunteer subjects within an age bracket of 19-48 years. Each subject performed six activities of daily living (ADL) -- WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING -- wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, data was captured representing 3-axial linear acceleration measurements and 3-axial angular velocity measurements at a constant rate of 50 Hz. The experiments were video-recorded to label the data manually. (An example of the 6 recorded activities with one of the participants can be seen by visiting the following [link](https://www.youtube.com/watch?v=XOEN9W05_4A).) The obtained data set was randomly partitioned into 2 subfolder trees:

* `train`: Data generated by 70% of the subjects (21 of 30);
* `test`: Data generated by the remaining 30% of subjects (9 of 30).

The accelerometer and gyroscope sensor signals (tAcc-XYZ and tGyro-XYZ, respectively, where "t" denotes that these are time domain signals) were pre-processed by applying noise filters -- a median filter and a 3rd-order Butterworth low-pass filter with a corner frequency of 20 Hz -- and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ, respectively) using another Butterworth low-pass filter, one with a corner frequency of 0.3 Hz. The gravitational force is assumed to have only low frequency components; therefore, a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also, the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). Finally, a Fast Fourier Transform (FFT) was applied to some of these signals to produce additional signals (fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, and fBodyGyroJerkMag, where "f" denotes that these are frequency domain signals). Together, these signals were used to estimate variables of the feature vector for each pattern, using "-XYZ" to denote 3-axial signals in the X, Y and Z directions.

For each record in the data set, the following are provided:

* 3-axial acceleration from the accelerometer (total acceleration) and the estimated body acceleration;
* 3-axial angular velocity from the gyroscope;
* A 561-feature vector with time and frequency domain variables;
* The record's activity label;
* An ID of the subject who participated in the experiment.

For a full description, refer to the site where the data was obtained:

http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

## Source Data

Source data for this project was downloaded from the Machine Learning Repository, hosted by the Center for Machine Learning and Intelligent Systems at the University of California, Irvine (UCI):

https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip

Data files that were used from this source are:

* `activity_labels.txt`: 6 class labels and the respect activity name of each.
* `features.txt`: List of all 561 statistical features, each one a statistical summary of a measurement captured by the smartphone's accelerometer or gyroscope.
* `test/subject_test.txt`: 2,947 integers, each denoting the ID (1 to 30) of the test subject who performed the activity for each window sample.
* `train/subject_train.txt`: 7,352 integers, each denoting the ID (1 to 30) of the training subject who performed the activity for each window sample.
* `test/X_test.txt`: Test set (9 of 30 subjects) representing 2,947 observations of the 561 measured features.
* `train/X_train.txt`: Training set (21 of 30 subjects) representing 7,352 observations of the 561 statistical features.
* `test/y_test.txt`: 2,947 integers, each representing an activity label for a test subject (9 of 30).
* `train/y_train.txt`: 7,352 integers, each representing an activity label for a training subject (21 of 30).

Data files that were available from the download but considered extraneous to the project's goal and therefore ignored are those found in the `Inertial Signals` subfolder of both `test` and `train`.

### Target Data

An R script, `run_analysis.R`, was created to consolidate and summarize the source data into a single target data set, `tidied.csv`.  The resulting output is a tidier version of the data that computes the mean for 66 of the 561 statistical features for each combination of subject and activity.  Each of the 66 extracted features corresponds to the mean or standard deviation for a particular cellphone accelerometer or gyroscope measurement.

In the subsections that follow, note that the number preceding the variable denotes the variable's position within the CSV file.

#### Categorical Variables

    1. Subject
    2. Activity

#### Measure Variables (Time Domain)

Body Acceleration (Accelerometer)

    3. tBodyAcc-mean()-X
    4. tBodyAcc-mean()-Y
    5. tBodyAcc-mean()-Z
    6. tBodyAcc-std()-X
    7. tBodyAcc-std()-Y
    8. tBodyAcc-std()-Z
    33. tBodyAccMag-mean()
    34. tBodyAccMag-std()

Gravity Acceleration (Accelerometer)

    9. tGravityAcc-mean()-X
    10. tGravityAcc-mean()-Y
    11. tGravityAcc-mean()-Z
    12. tGravityAcc-std()-X
    13. tGravityAcc-std()-Y
    14. tGravityAcc-std()-Z
    35. tGravityAccMag-mean()
    36. tGravityAccMag-std()

Body Acceleration Jerk (Accelerometer)

    15. tBodyAccJerk-mean()-X
    16. tBodyAccJerk-mean()-Y
    17. tBodyAccJerk-mean()-Z
    18. tBodyAccJerk-std()-X
    19. tBodyAccJerk-std()-Y
    20. tBodyAccJerk-std()-Z
    37. tBodyAccJerkMag-mean()
    38. tBodyAccJerkMag-std()
    
Body Angular Velocity (Gyroscope)

    21. tBodyGyro-mean()-X
    22. tBodyGyro-mean()-Y
    23. tBodyGyro-mean()-Z
    24. tBodyGyro-std()-X
    25. tBodyGyro-std()-Y
    26. tBodyGyro-std()-Z
    39. tBodyGyroMag-mean()
    40. tBodyGyroMag-std()

Body Angular Velocity Jerk (Gyroscope)

    27. tBodyGyroJerk-mean()-X
    28. tBodyGyroJerk-mean()-Y
    29. tBodyGyroJerk-mean()-Z
    30. tBodyGyroJerk-std()-X
    31. tBodyGyroJerk-std()-Y
    32. tBodyGyroJerk-std()-Z
    40. tBodyGyroJerkMag-mean()
    41. tBodyGyroJerkMag-std()

#### Measure Variables (Frequency Domain)

Body Acceleration (Accelerometer)

    43. fBodyAcc-mean()-X
    44. fBodyAcc-mean()-Y
    45. fBodyAcc-mean()-Z
    46. fBodyAcc-std()-X
    47. fBodyAcc-std()-Y
    48. fBodyAcc-std()-Z
    61. fBodyAccMag-mean()
    62. fBodyAccMag-std()

Body Acceleration Jerk (Accelerometer)

    49. fBodyAccJerk-mean()-X
    50. fBodyAccJerk-mean()-Y
    51. fBodyAccJerk-mean()-Z
    52. fBodyAccJerk-std()-X
    53. fBodyAccJerk-std()-Y
    54. fBodyAccJerk-std()-Z
    63. fBodyBodyAccJerkMag-mean()
    64. fBodyBodyAccJerkMag-std()

Body Angular Velocity (Gyroscope)

    55. fBodyGyro-mean()-X
    56. fBodyGyro-mean()-Y
    57. fBodyGyro-mean()-Z
    58. fBodyGyro-std()-X
    59. fBodyGyro-std()-Y
    60. fBodyGyro-std()-Z
    65. fBodyBodyGyroMag-mean()
    66. fBodyBodyGyroMag-std()

Body Angular Velocity Jerk (Gyroscope)

    27. fBodyGyroJerk-mean()-X
    28. fBodyGyroJerk-mean()-Y
    29. fBodyGyroJerk-mean()-Z
    30. fBodyGyroJerk-std()-X
    31. fBodyGyroJerk-std()-Y
    32. fBodyGyroJerk-std()-Z
    67. fBodyBodyGyroJerkMag-mean()
    68. fBodyBodyGyroJerkMag-std()

## ETL Algorithm

The steps below list data processing operations -- collectively called extract, transform, load (ETL) in industry -- executed by the R script (`run_analysis.R`) to create the tidy data set (`tidied.csv`).

1. Merge the training and the test sets to create one data set.
 1. Download data.
 2. Read source data.
 3. Merge training and test data by rows for each domain (`subject`, `X`, and `y`).
 4. Add column names.
2. Extract only the measurements on the mean and standard deviation for each measurement.
 1. Identify column names containing `mean()` or `std()`.
 2. Keep the columns for extraction and the following column exceptions: `Subject` and `Activity`.
3. Uses descriptive activity names to name the activities in the data set.
 1. Identify factor levels and labels.
 2. Create factors.
4. Appropriately labels the data set with descriptive variable names.
5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
 1. Identify categorical (i.e., ID) and measure columns.
 2. Reshape data and compute mean (average).
 3. Write tidy data set to a CSV file.

## References

1. Source data: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
2. Full description of source data: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
3. Article on wearable computing: http://www.insideactivitytracking.com/data-science-activity-tracking-and-the-battle-for-the-worlds-top-sports-brand/
